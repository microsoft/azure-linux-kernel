From 3ef3d759f5f8d6fcf33c5efdad3a9cf2e8a75bee Mon Sep 17 00:00:00 2001
From: Matthew Finlay <matt@mellanox.com>
Date: Mon, 22 Feb 2016 18:17:33 +0200
Subject: net/mlx5e: Add TX stateless offloads for tunneling
Reply-To: joseph.salisbury@microsoft.com

Add support for TSO and TX checksum when using hw assisted,
tunneled offloads.

Signed-off-by: Matthew Finlay <matt@mellanox.com>
Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
Signed-off-by: David S. Miller <davem@davemloft.net>
(backported from commit 9879515895ffe46a424d00ad5ce92e32fd61790b)
Signed-off-by: Joseph Salisbury <joseph.salisbury@microsoft.com>
---
 .../net/ethernet/mellanox/mlx5/core/en_tx.c   | 25 +++++++++++++------
 include/linux/skbuff.h                        |  5 ++++
 2 files changed, 23 insertions(+), 7 deletions(-)

diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_tx.c b/drivers/net/ethernet/mellanox/mlx5/core/en_tx.c
index 9a4c4f010a19..2f9517831f16 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_tx.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_tx.c
@@ -1,5 +1,5 @@
 /*
- * Copyright (c) 2015, Mellanox Technologies. All rights reserved.
+ * Copyright (c) 2015-2016, Mellanox Technologies. All rights reserved.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
@@ -186,9 +186,14 @@ static netdev_tx_t mlx5e_sq_xmit(struct mlx5e_sq *sq, struct sk_buff *skb)
 
 	memset(wqe, 0, sizeof(*wqe));
 
-	if (likely(skb->ip_summed == CHECKSUM_PARTIAL))
-		eseg->cs_flags	= MLX5_ETH_WQE_L3_CSUM | MLX5_ETH_WQE_L4_CSUM;
-	else
+	if (likely(skb->ip_summed == CHECKSUM_PARTIAL)) {
+		eseg->cs_flags = MLX5_ETH_WQE_L3_CSUM;
+		if (skb->encapsulation)
+			eseg->cs_flags |= MLX5_ETH_WQE_L3_INNER_CSUM |
+					  MLX5_ETH_WQE_L4_INNER_CSUM;
+		else
+			eseg->cs_flags |= MLX5_ETH_WQE_L4_CSUM;
+	} else
 		sq->stats.csum_offload_none++;
 
 	if (sq->cc != sq->prev_cc) {
@@ -201,9 +206,15 @@ static netdev_tx_t mlx5e_sq_xmit(struct mlx5e_sq *sq, struct sk_buff *skb)
 
 		eseg->mss    = cpu_to_be16(skb_shinfo(skb)->gso_size);
 		opcode       = MLX5_OPCODE_LSO;
-		ihs          = skb_transport_offset(skb) + tcp_hdrlen(skb);
-		payload_len  = skb->len - ihs;
-		num_bytes = skb->len + (skb_shinfo(skb)->gso_segs - 1) * ihs;
+
+		if (skb->encapsulation)
+			ihs = skb_inner_transport_offset(skb) + inner_tcp_hdrlen(skb);
+		else
+			ihs = skb_transport_offset(skb) + tcp_hdrlen(skb);
+
+		payload_len   = skb->len - ihs;
+		wi->num_bytes = skb->len +
+				(skb_shinfo(skb)->gso_segs - 1) * ihs;
 		sq->stats.tso_packets++;
 		sq->stats.tso_bytes += payload_len;
 	} else {
diff --git a/include/linux/skbuff.h b/include/linux/skbuff.h
index ae94d8b642b0..b57dcaf7772e 100644
--- a/include/linux/skbuff.h
+++ b/include/linux/skbuff.h
@@ -1971,6 +1971,11 @@ static inline unsigned char *skb_inner_transport_header(const struct sk_buff
 	return skb->head + skb->inner_transport_header;
 }
 
+static inline int skb_inner_transport_offset(const struct sk_buff *skb)
+{
+        return skb_inner_transport_header(skb) - skb->data;
+}
+
 static inline void skb_reset_inner_transport_header(struct sk_buff *skb)
 {
 	skb->inner_transport_header = skb->data - skb->head;
-- 
2.17.1

